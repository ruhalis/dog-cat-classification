{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML\\dog-cat-classification\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/dog-and-cat-classification-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 775M/775M [04:06<00:00, 3.30MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ruhalis\\.cache\\kagglehub\\datasets\\bhavikjikadara\\dog-and-cat-classification-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Grayscale(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root='PetImages', transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader objects for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # first hidden layer\n",
    "        self.fc2 = nn.Linear(512, 256)          # second hidden layer\n",
    "        self.fc3 = nn.Linear(256, 128)           # third hidden layer\n",
    "        self.fc4 = nn.Linear(128, 64) \n",
    "        self.fc5 = nn.Linear(64, num_classes)  # output layer\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten the image tensor: from (batch_size, 1, 64, 64) to (batch_size, 1*64*64)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)  # raw logits output; CrossEntropyLoss will apply softmax\n",
    "        return x\n",
    "\n",
    "# Calculate the input size (grayscale image has one channel)\n",
    "input_size = 1 * 256 * 256\n",
    "# Number of classes determined from the dataset (should be 2 for your two classes)\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleClassifier(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (fc1): Linear(in_features=65536, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML\\dog-cat-classification\\venv\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6871\n",
      "Validation Accuracy: 60.30%\n",
      "Epoch [2/10], Loss: 0.6533\n",
      "Validation Accuracy: 60.88%\n",
      "Epoch [3/10], Loss: 0.6393\n",
      "Validation Accuracy: 61.36%\n",
      "Epoch [4/10], Loss: 0.6229\n",
      "Validation Accuracy: 62.80%\n",
      "Epoch [5/10], Loss: 0.5972\n",
      "Validation Accuracy: 63.08%\n",
      "Epoch [6/10], Loss: 0.5793\n",
      "Validation Accuracy: 62.56%\n",
      "Epoch [7/10], Loss: 0.5497\n",
      "Validation Accuracy: 63.70%\n",
      "Epoch [8/10], Loss: 0.5175\n",
      "Validation Accuracy: 64.00%\n",
      "Epoch [9/10], Loss: 0.4766\n",
      "Validation Accuracy: 60.32%\n",
      "Epoch [10/10], Loss: 0.4403\n",
      "Validation Accuracy: 61.94%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  \n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Dog\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Specify the path to your test image\n",
    "image_path = 'dog.jpg'\n",
    "\n",
    "# Open the image using PIL\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Apply the same transformation pipeline used during training\n",
    "# (This converts the image to 64x64, grayscale, tensor and normalizes it)\n",
    "image = transform(image)\n",
    "\n",
    "# Add a batch dimension since the model expects a batch of images\n",
    "image = image.unsqueeze(0).to(device)\n",
    "\n",
    "# Set the model to evaluation mode and perform inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    # Get the predicted class (index of the highest logit)\n",
    "    _, predicted_class = torch.max(outputs, 1)\n",
    "\n",
    "# Print the predicted class name\n",
    "print(\"Predicted class:\", dataset.classes[predicted_class.item()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
